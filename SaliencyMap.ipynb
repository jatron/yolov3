{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jorge's cell\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import models\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import utils.datasets\n",
    "import utils.torch_utils\n",
    "import utils.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download COCO 2014 dataset (20GB):\n",
    "!cwd=$(pwd) && cd .. && ${cwd}/data/get_coco_dataset_gdrive.sh && cd $cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hyp = {\n",
    "    'giou': 3.31,   # giou loss gain\n",
    "    'cls': 42.4,    # cls loss gain\n",
    "    'cls_pw': 1.0,  # cls BCELoss positive_weight\n",
    "    'obj': 52.0,    # obj loss gain (*=img_size/416 if img_size != 416)\n",
    "    'obj_pw': 1.0,  # obj BCELoss positive_weight\n",
    "    'iou_t': 0.213  # iou training threshold\n",
    "}\n",
    "\n",
    "# Other variables\n",
    "architecture = \"default\"\n",
    "cfg = \"cfg/yolov3-spp.cfg\"\n",
    "data = \"data/coco_64img.data\"\n",
    "path = \"data/coco_64img.txt\"\n",
    "weights = \"weights/ultralytics49.pt\"\n",
    "output_dir = \"output/\"\n",
    "source_dir = \"data/source/\"\n",
    "grad_filename = \"grad.bmp\"\n",
    "original_filename = \"original.jpg\"\n",
    "detect_filename = \"detect.jpg\"\n",
    "number_of_classes = 80\n",
    "\n",
    "# Initialize model\n",
    "device = utils.torch_utils.select_device()\n",
    "model = models.Darknet(cfg=cfg).to(device)\n",
    "model.hyp = hyp               # attach hyperparameters to model\n",
    "model.nc = number_of_classes  # attach number of classes to model\n",
    "model.arc = architecture      # attach yolo architecture\n",
    "\n",
    "# Load weights\n",
    "models.attempt_download(weights)\n",
    "if weights.endswith('.pt'):  # pytorch format\n",
    "    model.load_state_dict(torch.load(weights, map_location=device)['model'])\n",
    "else:  # darknet format\n",
    "    _ = models.load_darknet_weights(model, weights)\n",
    "\n",
    "# Dataset\n",
    "dataset = utils.datasets.LoadImagesAndLabels(path)\n",
    "\n",
    "def compute_saliency_map(index):\n",
    "    # Compute gradient with respect to pixels\n",
    "    img, target, img_path, _ = dataset[index]\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device)\n",
    "    target = target.to(device)\n",
    "    img.requires_grad = True\n",
    "    pred = model(img)    \n",
    "    loss, _ = utils.utils.compute_loss(pred, target, model)\n",
    "    loss.backward()\n",
    "    img.requires_grad = False\n",
    "    grad = img.grad\n",
    "    img, grad = img.squeeze(), grad.squeeze()\n",
    "\n",
    "    # Convert pixel gradients to grayscale image \n",
    "    grad = np.sum(np.absolute(grad.numpy()), axis=0)\n",
    "    for i in range(1, 1000):\n",
    "        max_idx = np.unravel_index(np.argmax(grad, axis=None), grad.shape)\n",
    "        grad = grad / grad[max_idx] * 255\n",
    "        print(\"average:\", np.average(grad))\n",
    "        if (np.average(grad) < 48):\n",
    "            grad = grad / (192 * i)\n",
    "            grad = np.log(grad + 1)\n",
    "        else:\n",
    "            break\n",
    "    grad = grad.astype(int)\n",
    "\n",
    "    # Plot pixel gradients\n",
    "    plt.imshow(grad, cmap='Greys')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot original image\n",
    "    img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    # Prepare environment\n",
    "    !rm -rf $output_dir\n",
    "    !mkdir $output_dir\n",
    "    !rm -rf $source_dir\n",
    "    !mkdir $source_dir\n",
    "    !cp $img_path $source_dir\n",
    "\n",
    "    # Detect bounding boxes\n",
    "    !python3 detect.py --cfg $cfg --data $data --weights $weights --source $source_dir\n",
    "\n",
    "    # Write pixel gradients to file\n",
    "    cv2.imwrite(output_dir + grad_filename, grad)\n",
    "\n",
    "    # Write original image to file\n",
    "    img = img * 255\n",
    "    img = img[:, :, [2, 1, 0]]  # Convert from RGB to BGR\n",
    "    cv2.imwrite(output_dir + original_filename, img)\n",
    "\n",
    "    # Plot original image with detected bounding boxes\n",
    "    detect_img_path = output_dir + os.path.split(img_path)[1]\n",
    "    img = cv2.imread(detect_img_path)\n",
    "    img = img[:, :, [2, 1, 0]] # Convert from BGR to RGB\n",
    "    img, _, _ = utils.datasets.letterbox(img=img, auto=False)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    # Write original image with detected bounding boxes to file\n",
    "    img = img[:, :, [2, 1, 0]]  # Convert from RGB to BGR\n",
    "    cv2.imwrite(output_dir + detect_filename, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_map_dir = \"saliency_map_output/\"\n",
    "\n",
    "!rm -rf saliency_map_output\n",
    "!mkdir saliency_map_output\n",
    "for i in range(40):\n",
    "    compute_saliency_map(i)\n",
    "    path_full_size_detect = saliency_map_dir + \"COCO\" + str(i) + \".jpg\"\n",
    "    path_grad = saliency_map_dir + \"grad\" + str(i) + \".bmp\"\n",
    "    path_detect = saliency_map_dir + \"detect\" + str(i) + \".jpg\"\n",
    "    path_original = saliency_map_dir + \"original\" + str(i) + \".jpg\"\n",
    "    !cp output/COCO* $path_full_size_detect\n",
    "    !cp output/grad.bmp $path_grad\n",
    "    !cp output/detect.jpg $path_detect\n",
    "    !cp output/original.jpg $path_original"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
